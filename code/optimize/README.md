# 优化算法可视化项目

一个专业的优化算法可视化框架，支持多种优化算法的实现、可视化和比较分析。

## 🚀 项目特色

- **模块化设计**: 采用策略模式，将算法实现与可视化完全分离，易于扩展。
- **自动算法发现**: 无需手动注册，新的优化算法可以被自动发现和加载。
- **丰富的可视化**: 实时动画展示优化过程，支持GIF导出。
- **统一配置管理**: YAML配置文件管理所有参数和路径。
- **多种测试函数**: 内置常用的优化测试函数。
- **通用比较工具**: 支持任意算法的性能比较。

## 🛠️ 安装依赖

```bash
pip install numpy matplotlib pyyaml pillow
```

## 🎯 快速开始

### 1. 运行示例
```bash
python main.py
```

### 2. 使用命令行界面
```bash
# 运行梯度下降算法
python main.py gradient_descent quadratic --x0 5.0 --learning_rate 0.1

# 比较不同学习率
python main.py gradient_descent quadratic --x0 5.0 --compare-learning-rates 0.01 0.1 0.5

# 比较梯度下降的变体
python main.py gradient_descent quadratic --x0 5.0 --compare-variants
```

## 📊 支持的算法与数学原理

### 1. 梯度下降 (Gradient Descent)

**核心思想:**
梯度下降是最基础的一阶优化算法。其核心思想是，函数在某一点的梯度方向是函数值增长最快的方向，那么梯度的反方向就是函数值下降最快的方向。因此，通过沿着梯度的反方向小步迭代，可以逐步逼近函数的局部最小值。

**更新规则:**
$x_{t+1} = x_t - \eta \cdot \nabla f(x_t)$

**参数详解:**
- $x_t$: 第 $t$ 次迭代时的参数位置。
- $\eta$ (学习率): 一个超参数，决定了每次迭代的步长。如果 $\eta$ 太小，收敛速度会很慢；如果太大，可能会在最小值附近振荡甚至发散。
- $\nabla f(x_t)$: 目标函数 $f$ 在点 $x_t$ 处的梯度。它指向函数值增长最快的方向。

**优缺点:**
- **优点**: 原理简单，易于实现。
- **缺点**: 学习率需要手动调整；在平坦区域收敛缓慢；在陡峭区域容易振荡。

### 2. 动量梯度下降 (Momentum Gradient Descent)

**核心思想:**
动量法模拟了物理学中物体的动量概念。它在梯度下降的基础上引入了一个“动量”项，该项累积了过去迭代中的梯度信息。这有助于在相关方向上加速收敛，并抑制在无关方向上的振荡。

**更新规则:**
$v_{t+1} = \gamma v_t + \eta \cdot \nabla f(x_t)$
$x_{t+1} = x_t - v_{t+1}$

**参数详解:**
- $v_t$: 第 $t$ 次迭代时的速度（或动量），是过去梯度的指数加权平均。
- $\gamma$ (动量系数): 一个介于 0 和 1 之间的超参数，控制了过去动量对当前更新的影响程度。典型值为 0.9。

**优缺点:**
- **优点**: 加速收敛，尤其是在梯度方向基本一致的情况下；能有效抑制振荡。
- **缺点**: 仍然需要手动调整学习率。

### 3. Nesterov 加速梯度 (NAG)

**核心思想:**
NAG 是对标准动量法的一种改进。标准动量法首先计算当前点的梯度，然后结合动量进行更新。而 NAG 则先沿着动量的方向“预走”一步，然后在那个“预测”的位置计算梯度，并用这个梯度来修正最终的更新方向。这种“向前看”的策略使其更加智能，能提前感知到即将到来的斜率变化，从而减速。

**更新规则:**
$v_{t+1} = \gamma v_t + \eta \cdot \nabla f(x_t - \gamma v_t)$
$x_{t+1} = x_t - v_{t+1}$

**参数详解:**
- $\nabla f(x_t - \gamma v_t)$: 在“预测”位置 $x_t - \gamma v_t$ 计算的梯度。

**优缺点:**
- **优点**: 通常比标准动量法收敛更快，效果更好。
- **缺点**: 实现比标准动量法略复杂。

### 4. Adagrad (Adaptive Gradient Algorithm)

**核心思想:**
Adagrad 是一种自适应学习率算法。它为模型中的每个参数分配一个独立的学习率。其核心思想是：对于更新频繁的参数，使用较小的学习率；对于更新不频繁的参数，使用较大的学习率。

**更新规则:**
$g_{t,i} = \nabla f(x_{t,i})$
$G_{t,ii} = G_{t-1,ii} + g_{t,i}^2$
$x_{t+1,i} = x_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}} \cdot g_{t,i}$

**参数详解:**
- $G_t$: 一个对角矩阵，其对角线元素 $G_{t,ii}$ 是参数 $x_i$ 历史上所有梯度的平方和。
- $\epsilon$: 一个极小的平滑项，用于防止分母为零。

**优缺点:**
- **优点**: 无需手动调整学习率。
- **缺点**: 随着训练的进行，分母中的梯度平方和会不断累积，导致学习率单调递减并最终变得非常小，从而提前停止学习。

### 5. RMSprop (Root Mean Square Propagation)

**核心思想:**
RMSprop 是对 Adagrad 的一种改进，旨在解决其学习率过早衰减的问题。它不再累积所有历史梯度的平方，而是采用指数加权移动平均来计算梯度的平方。

**更新规则:**
$E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma) g_t^2$
$x_{t+1} = x_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \cdot g_t$

**参数详解:**
- $E[g^2]_t$: 梯度平方的指数加权移动平均。
- $\gamma$: 衰减率，控制了历史梯度信息的影响范围。

**优缺点:**
- **优点**: 解决了 Adagrad 学习率过早衰减的问题，在非凸问题上表现良好。
- **缺点**: 仍然需要设置一个全局学习率 $\eta$。

### 6. Adam (Adaptive Moment Estimation)

**核心思想:**
Adam 算法结合了 Momentum 和 RMSprop 的优点。它既像 Momentum 一样计算梯度的一阶矩（均值）的指数加权移动平均，也像 RMSprop 一样计算梯度的二阶矩（方差）的指数加权移动平均。

**更新规则:**
$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$
$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$
$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$
$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$
$x_{t+1} = x_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$

**参数详解:**
- $m_t, v_t$: 梯度的一阶和二阶矩的估计。
- $\hat{m}_t, \hat{v}_t$: 对 $m_t, v_t$ 的偏差修正，用于解决在训练初期估计不准的问题。
- $\beta_1, \beta_2$: 矩估计的指数衰减率。

**优缺点:**
- **优点**: 结合了多种算法的优点，在各种场景下都表现出色，是目前最常用的优化算法之一。
- **缺点**: 参数较多，但通常使用默认值即可。

### 7. 牛顿法 (Newton's Method)

**核心思想:**
牛顿法是一种二阶优化算法。它不仅使用梯度（一阶导数），还使用 Hessian 矩阵（二阶导数）来指导搜索方向。其基本思想是对目标函数在当前点进行二阶泰勒展开，然后找到这个二次近似函数的最小值点作为下一次迭代的位置。

**更新规则:**
$x_{t+1} = x_t - [H f(x_t)]^{-1} \nabla f(x_t)$

**参数详解:**
- $H f(x_t)$: 目标函数在 $x_t$ 处的 Hessian 矩阵。
- $[H f(x_t)]^{-1}$: Hessian 矩阵的逆。

**优缺点:**
- **优点**: 收敛速度快（二次收敛）。
- **缺点**: 计算 Hessian 矩阵及其逆矩阵的成本非常高，尤其是在高维问题中。

### 8. BFGS (Broyden–Fletcher–Goldfarb–Shanno)

**核心思想:**
BFGS 是一种拟牛顿法，旨在解决牛顿法中计算 Hessian 矩阵逆的巨大开销问题。它不再直接计算 Hessian 矩阵的逆，而是通过迭代地更新一个对 Hessian 矩阵逆的近似来实现。

**优缺点:**
- **优点**: 在保持较快收敛速度的同时，避免了计算 Hessian 矩阵逆的高昂成本。
- **缺点**: 实现比一阶方法复杂。

## 🚀 扩展开发

### 添加新算法

1.  在 `algorithms/` 目录下创建一个新的 Python 文件。
2.  创建一个继承自 `OptimizationAlgorithm` 的类。
3.  实现 `optimize` 方法。
4.  使用 `@register_algorithm('your_algorithm_name')` 装饰器注册你的类。

## 📝 许可证

本项目采用 MIT 许可证。
